The past decade has witnessed the meteoric rise of AI-generated visual media. With the advent of Convolutional Neural Networks (CNNs), Diffusion Models and Generative-Adversarial-Networks (GANs), machine generated images/videos have reached a level of sophistication where they can easily fool a human observer. Deep learning techniques have facilitated the training of larger and more powerful generative models. Architectural innovations such as progressive growing, self-attention mechanisms, and spectral normalization have improved the stability and convergence of GAN training, leading to the creation of high-resolution and diverse images across various domains. 

However, the widespread adoption of AI-generated images also raises ethical and societal considerations. Issues such as copyright, authenticity, and bias in generated content pose challenges that need to be addressed as these technologies continue to evolve. Moreover, the democratization of AI-generated images raises questions about the future of human creativity and the role of artificial intelligence in artistic expression. As such, there is a need for techniques to identify media that is machine-generated. 

Previous work from Wang et al. (2019)  \cite{3} suggested that images generated by Convolutional Neural Network are easy to distinguish from actual original photos due to the retention of identifiable fingerprints. These telltale signs allow forensic classifiers to discern between models with minimal adaptation required. These distinctive markers arise from various factors such as the dataset used for training and the unique architecture of the convolutional neural network. This feature aids in accurately distinguishing synthetic visuals from authentic ones. Gragnaniello et al. (2021)  \cite{4} has discussed several models based on differing techniques including CNN-based image classification, gaussian blurring, image spectrum analysis, etc. this study showed the significant gap in achieving dependable tools for GAN image detection. Discrepancies between training and testing data, along with issues like compression and resizing, were considerable challenges. But this analysis did not offer valuable insights into the essential components of effective solutions, offering valuable cues for future research endeavors. However, most of this work focuses on image-generation via GANs. 

Latent diffusion models, on the other hand, offer a promising alternative to CNN or GAN-generated images as they have achieved higher image quality superior to other generative models as can be noted in the work of Dhariwal and Nichol (2021)  \cite{5}, providing higher fidelity, greater diversity, better preservation of semantic information, reduced mode collapse, and increased robustness to adversarial attacks. These models are less prone to mode collapse due to the nature of the diffusion process, which encourages exploration of the entire data distribution and leverage diffusion processes to gradually refine the image over multiple steps, resulting in smoother transitions and more coherent details. They can generate a broader range of diverse images compared to CNN or GAN models. The diffusion process allows for more controlled exploration of the latent space, leading to the generation of a wider variety of visually appealing outputs.

The work by Rombach et al. (2021)  \cite{2} introduced latent diffusion models as a straightforward and effective method to enhance the training and sampling efficiency of denoising diffusion models without compromising their quality. Leveraging this approach alongside the cross-attention conditioning mechanism, the study showcased superior outcomes compared to leading methods across various conditional image synthesis tasks, all achieved without requiring task-specific architectures. 

Thus, with the recent development and increase in public-access of Latent Diffusion  models (like Stable Diffusion 1.4), newer methods are required to cope with the ever-increasing quality of machine generated media. Additionally, this effect has also made available increasingly larger and previously absent datasets such as CIFAKE (2024)  \cite{6}, that has a set of real and fake images containing 120,000 images  out of which 60,000 images are from the existing CIFAR-10 (2009)  \cite{7} dataset which is a popular dataset used for various tasks in computer vision and machine learning and 60,000 images synthesized. 

Deep learning has transformed the landscape of image recognition, bringing in a new era of highly accurate and efficient systems. Convolutional Neural Networks (CNNs) are  specialized architectures designed to process grid-like data such as images. By leveraging multiple layers of convolutional and pooling operations, CNNs can automatically learn hierarchical representations of images, capturing both simple features like edges and complex structures like objects. These networks are trained on large datasets of labeled images, where they learn to associate input images with corresponding labels through iterative optimization of internal parameters. 

Transfer learning further accelerates this process by allowing pre-trained models to be fine-tuned for specific tasks, facilitating faster training and improved performance, particularly when labeled data is scarce. The work of He et. al (2015) \cite{8} presented a residual learning framework to simplify the process of training networks relatively deeper than prior ones.  The layers are explicitly redefined as learning residual functions concerning the inputs of each layer. Through extensive empirical analysis, it was shown that these residual networks are more amenable to optimization and can achieve improved accuracy with substantially greater depth.

Optimization involves identifying the optimal solution among a set of alternatives for a given problem. In the realm of deep learning applications, meta-heuristic algorithms emerge as potent tools for solving complex problems. These algorithms draw inspiration from natural phenomena and the logical behavior observed in physical systems. They excel in finding acceptable solutions with comparatively lower computational resources and within a reasonable time frame. By mimicking the processes found in nature, meta-heuristic algorithms offer efficient ways to navigate vast solution spaces and identify solutions that meet specified criteria. Their ability to strike a balance between exploration and exploitation makes them invaluable in tackling challenging optimization tasks encountered in deep learning, yielding results that are both effective and efficient. Metaheuristic algorithms are high-level techniques that are used to find close-to-optimal solutions within optimization problems suffering from large search spaces that are complex and difficult to find optimal solutions for. Since the advent of the first such algorithm- the Genetic Algorithm  \cite{9} in the 1960s, several different variations and classes of metaheuristics have become popular. Some of them are Particle Swarm Optimization  \cite{10}, Artificial Bee Colony Optimization  \cite{11}, Gray Wolf Optimizer  \cite{12}, etc. 

A widespread application of such metaheuristics is to solve the problem of Feature Subset Selection for machine learning problems, the work pertaining to which was reviewed by Agarwal et al.  \cite{13}which provided an extensive examination of research literature based on addressing feature selection through the utilization of metaheuristic algorithms developed over the decade 2009-2019. Metaheuristic optimization techniques provide significant benefits to convolutional neural networks (CNNs) in the domain of image classification. Through the utilization of metaheuristic algorithms such as Genetic Algorithms (GA) and Particle Swarm Optimization (PSO), CNNs can effectively navigate through hyperparameter spaces, resulting in the discovery of optimal setups for crucial parameters such as learning rates, batch sizes, and network architectures. These algorithms play a vital role in architecture searches, empowering CNNs to dynamically adjust their structures to better suit the complexity of the dataset at hand. Moreover, metaheuristic optimization contributes to feature selection or extraction, enabling the identification of key image features essential for accurate classification tasks.

Within CNN-based image classification, metaheuristics can be used to select features from those a CNN extracts from a dataset, as can be noted in the work of Basu et al. (2022) \cite{14} where for feature extraction, the study used three Convolutional Neural Networks (CNNs) and for feature selection, the study employed a meta-heuristic optimization algorithm technique, Harmony Search (HS), combined with a local search method for improved accuracy and obtained results far superior than various algorithms used on the dataset of CT-scan images in the field of COVID-19 detection. The work of El-Kenawy et al. (2020)  \cite{15} proposed a framework with feature extraction from a Convolutional Neural Network and used Guided Whale Optimization Algorithm for feature selection to diagnose COVID-19 disease in chest CT-scan images and achieved much greater performance compared to other classifiers.



Application of this technique that has been implemented in medical image classification of chest CT-scan images in COVID-19 disease detection, can be particularly successful within the field of AI-generated image detection given that these photorealistic images tend to have certain local features (like fingers in human portraits) that differ from real images.  
